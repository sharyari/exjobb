\newpage
\section{Introduction}
Todays society grows more and more dependent on computer applications. Often they are used directly, for example the task of paying one's bills online. In other cases, applications are aiding us in a more abstract manner, e.g. controlling the elevator or planning a train schedule. The common factor between the online bank, the elevator relay and the train scheduler is that the correctness of these programs is of utter importance, where program failure could have devastating results on the economy, the infrastructure or even cause harm.

This has motivated research on various techniques to find and correct potential faults, particularly in safety-critical systems. The most common technique is that of \e{testing}, i.e. observing the system behaviour on a variety of likely or even unlikely scenarious. The widespread use of testing is well-motivated, but there are several scenarios, where testing by itself is insufficient, or difficult to carry out. It would for example be costly to verify the correctness of the aforementioned elevator only by testing, as a failure could result in damages on the system. Yet another weakness of this approach is that testing helps find faults at a late stage in the development process.

Another technique used for verification is the process of \e{simulation}. In contrast to testing, simulation can be done in an early stage of the development. Rather than first implementing an algorithm, one may simulate an abstracted model of the algorithm which may help ensure its correctness or find a fault in the algorithm before development has begun. An important note is that simulation techniques are not intended to be used \e{instead} of testing, but rather in combination with testing, as an abstract model of a system can never fully represent the system.

The goal of \e{model checking} is to formally verify the correctness of concurrent programs with respect to a given specification. %It builds upon fact that programs can be defined as mathematical , and thus, their correctness can be established using logical proofs. Although manual proofs have been and are still being used, most research efforts of formal verification today are directed against automatic verification methods.
In general, given a model of a system and a specification of its intended properties, the task is to decide whether or not a model meets its specification, by performing an exhaustive search in the system. Different representations of models and properties have been proposed. One of the most common methods -- temporal model checking -- expresses the model as a \e{finite state machine} and the properties as propositional logic formulae. These properties are then checked by creating a an abstract machine called a \e{state transition system} corresponding to the FSM at hand.

A serious limitation of this technique is the problem of \e{state space explosion}, i.e. an exponential increase of states in the transition system, in relation to the size of the finite state machine, i.e. a model of a program with a relatively small size may correspond to a transition system that may be of exponential size with respect of n.

A trend in todays computing is that applications become concurrent or distributed. This type of scenario create an issue similar to that of state space explosion, as the fact that a transition system corresponds to a finite state model does not imply that it is itself finite. This happens for example when the transition system corresponds to the composition of a possibly infinite number of programs, e.g. concurrent and distributed programs: we are often not interested in performing verification of a specific composition of concurrent programs, but rather in verifying that it works for any composition.

\e{Parameterized model checking} are systems composed of a number of the same FSM, where the the number of programs is itself a parameter of the system. This is often the case when discussing concurrent and distributed programs, and also in other types of programs such as cache coherence protocols and sensor systems\cite{zuck2004}. Although an undecidable problem in general, there are methods that can reduce the size of the problem to become finite and decidable in some cases. These methods include \e{counter abstraction techniques}\cite{counterabstraction} and \e{invisible invariant} generation\cite{invinv}. 

Yet an example of such a parameterized system is \cite{parosh} which takes advantage of the \e{small model property} -- if a small instance of a system is enough to exhibit the behaviour of the system in whole, that instance is a small model of the system. An important contribution of \cite{parosh} is that they show that this property holds for \e{quasi well-ordered systems}, and indicates its use for yet larger sets of systems. 

Using well-known techniques of \e{abstract interpretation} combined with the idea of small models, \cite{parosh} shows that model checking of systems with infinite programs can be reduced to a finite and decidable problem, and a software implementation of the algorithm substantiates this claim by emipirical results.

This essay draws the attention towards systems relying on communications over asynchronous unbounded buffers. This scenario is common in communication protocols and in distributed computing communicating over channels. An important note is that channel systems working on \e{perfect channels} are turing complete, and therefore undecidable -- as are parameterized systems in general -- it has been shown that model checking of channel systems over \e{lossy channels}, i.e. channels that may nondeterministicly lose messages, is decidable\cite{287591}\cite{gordon}.

Inspired by \cite{parosh}, I explore the possibility of using abstract interpretation techniques and small models to create parameterized systems for systems with unbounded buffers, keeping the number of programs constant. An implementation of the resulting model and verification technique was developed for this purpose. As previously mentioned, this is an undecidable problem in general, and this paper does \e{not} investigate exactly what class of systems that are decidable. The experimental results show that several well-known communication protocols are indeed in the scope of the tool.

\paragraph{Reading this paper} Section \ref{notation} introduces some of the terminology and notation used in this paper, whereas section \ref{definitions} contains formal definitions to some of the key concepts -- these are previously known concepts, asides from their adaption to the specific context of this thesis. Section \ref{model} introduces the concepts of small models and abstract interpretation, and relates these in the context of buffer channels to create the theoretical model for this paper. Section \ref{extensions} introduces some extensions to this model, allowing for a wider variety of modelling scenarios. In section \ref{implementation}, some abstractions and techniques are explained that allow for an efficient implementation of the verification algorithm. Further a protocol specification language is explained, that allows a user to define and use the verification tool without knowledge of the intricacies of the internal model. The results of the verifier when applied to a number of well-known communication algorithms is presented in section \ref{results}, as well as some comparisons against the results of other verification tools.

 	

%%% Local Variables:
%%% TeX-master: "report"
%%% End:
